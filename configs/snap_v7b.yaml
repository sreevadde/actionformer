# Snap Detection V7b - V2 backbone + Identity Conversion + All Improvements
#
# KEY INSIGHT: Current annotations have segments in FEATURE FRAME space (not seconds).
# Features are extracted at ~14.5/sec giving ~69ms temporal resolution.
# Using fps=1, stride=1, num_frames=1 creates identity conversion:
#   segment * 1 / 1 - 0.5 = segment (with minor offset)
#
# Post-processing conversion:
#   seconds = prediction_feature_frame / 14.5
#   video_frame = prediction_feature_frame / 14.5 * 59
#
# Combines:
# - Identity conversion for feature-frame annotations
# - V2 backbone: convTransformerv2 with RoPE, Flash Attention, SwiGLU, RMSNorm
# - Absolute position encoding (critical for temporal localization)
# - EIoU loss for better regression
# - DIoU-NMS for better post-processing

dataset_name: snap_v2
train_split: ['training']
val_split: ['validation']
devices: [0, 1, 2, 3]
init_rand_seed: 42

dataset: {
  json_file: /opt/dlami/nvme/fcv-snap/actionformer/annotations/snap_v5_single.json,
  feat_folder: /opt/dlami/nvme/fcv-snap/actionformer/features_v2,
  file_prefix: ~,
  file_ext: .npy,
  num_classes: 1,
  input_dim: 1024,

  # Identity conversion: segments are in feature frames
  # Features are ~14.5/sec, so 1 feature frame â‰ˆ 69ms
  default_fps: 1,
  feat_stride: 1,
  num_frames: 1,

  trunc_thresh: 0.5,
  crop_ratio: [0.9, 1.0],
  max_seq_len: 512,
}

model: {
  # V2 backbone with modern improvements
  backbone_type: convTransformerv2,
  use_abs_pe: true,      # CRITICAL: Absolute position for localization
  use_rope: true,        # Relative position via RoPE (complementary)
  use_flash_attn: true,  # Memory-efficient attention
  use_swiglu: true,      # Improved FFN activation
  use_rms_norm: true,    # Faster normalization

  fpn_type: identity,
  max_buffer_len_factor: 4.0,
  n_mha_win_size: 9,
  backbone_arch: [2, 2, 2],
  scale_factor: 2,

  # Regression ranges in feature frames
  # At ~14.5 feat/sec: [0,4] = 0-276ms, [4,8] = 276-552ms, [8,16] = 552-1104ms
  regression_range: [[0, 4], [4, 8], [8, 16]],

  num_classes: 1,
  embd_dim: 512,
  fpn_dim: 512,
  head_dim: 512,
  head_num_layers: 3,
}

opt: {
  learning_rate: 0.0002,  # Lower LR for v2 backbone stability
  epochs: 60,
  weight_decay: 0.05,
  schedule_type: cosine,
  warmup: True,
  warmup_epochs: 8,
}

loader: {
  batch_size: 16,
  num_workers: 4,
}

train_cfg: {
  init_loss_norm: 100,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  reg_loss_type: eiou,    # Enhanced IoU loss
}

test_cfg: {
  voting_thresh: 0.7,
  pre_nms_topk: 200,
  max_seg_num: 50,
  min_score: 0.001,
  multiclass_nms: True,
  nms_method: soft,
  nms_sigma: 0.7,
  iou_threshold: 0.1,
  use_diou_nms: true,     # Distance-aware NMS
  score_temperature: 1.0,
}

output_folder: ./ckpt/snap_v7b/
