# Snap Detection Config for ActionFormer
# Uses R3D-18 features extracted from NFL game footage

dataset_name: snap
train_split: ['training']
val_split: ['validation']
devices: [0]  # Single GPU (DataParallel has issues with dict inputs)
init_rand_seed: 42
dataset: {
  json_file: /opt/dlami/nvme/fcv-snap/actionformer/annotations/snap_detection.json,
  feat_folder: /opt/dlami/nvme/fcv-snap/actionformer/features,
  file_prefix: ~,
  file_ext: .npy,
  num_classes: 1,  # Single class: snap
  input_dim: 512,  # R3D-18 feature dimension
  feat_stride: 4,  # Frames per feature (stride=4 in extraction)
  num_frames: 16,  # Clip length for R3D-18
  # Data augmentation
  trunc_thresh: 0.5,
  crop_ratio: [0.9, 1.0],
  max_seq_len: 256,  # ~10 seconds at 60fps with stride 4
}
model: {
  fpn_type: identity,
  max_buffer_len_factor: 4.0,
  n_mha_win_size: 9,  # Smaller window for short action
  backbone_arch: [2, 2, 2],  # Lighter model for single class
  scale_factor: 2,
  regression_range: [[0, 4], [4, 8], [8, 16]],  # Shorter ranges for snap detection
}
opt: {
  learning_rate: 0.0001,
  epochs: 50,  # More epochs for smaller dataset
  weight_decay: 0.05,
}
loader: {
  batch_size: 16,  # Reasonable batch for single GPU
  num_workers: 8,  # More workers
}
train_cfg: {
  init_loss_norm: 100,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
}
test_cfg: {
  voting_thresh: 0.7,
  pre_nms_topk: 200,
  max_seg_num: 50,
  min_score: 0.001,
  multiclass_nms: False,  # Single class
  nms_sigma: 0.5,
}
output_folder: ./ckpt/snap_r3d18/
